{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "16624733\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('SQLs.txt').fillna(0)\n",
    "print(type(df))\n",
    "#x_np = pd.read_csv('data1000s').fillna(0)\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "#df['Sex'] = labelEncoder.fit_transform(df['Sex'])              \n",
    "#df['Cabin'] = labelEncoder.fit_transform(df['Cabin'])          \n",
    "#df['Embarked'] = labelEncoder.fit_transform(df['Embarked'])    \n",
    "\n",
    "x_np = np.array(df)\n",
    "print(type(x_np))\n",
    "#d = df[['Result']].to_dict('record')\n",
    "ds = pd.read_csv('SQLr.txt').to_dict('record')\n",
    "                                      \n",
    "#d = pd.read_csv('data1000r').to_dict('record')\n",
    "\n",
    "resultList = []\n",
    "for dd in ds:\n",
    "    d = \"0\"\n",
    "    dd = float(dd['Result'])\n",
    "    if dd == 'Result':\n",
    "        continue\n",
    "    if dd > 0:\n",
    "        d = \"-1\"\n",
    "    elif dd < 0:\n",
    "        d = \"1\"\n",
    "    dct = {'Result': d }\n",
    "    resultList.append(dct)\n",
    "#print(resultList)\n",
    "\n",
    "#print(x_np)\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "y_np = vectorizer.fit_transform(resultList)\n",
    "print(len(y_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "train_size = round(len(y_np) * 0.9)     # 全データの中でいくつ訓練データに回すか\n",
    "\n",
    "[x_train, x_test] = np.vsplit(x_np, [train_size]) # 入力データを訓練データとテストデータに分ける\n",
    "[y_train, y_test] = np.vsplit(y_np, [train_size]) # ラベルを訓練データをテストデータに分ける\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Size:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Size_1:0\", shape=(), dtype=int32)\n",
      "Epoch: 0001cost=667845.775892968\n",
      "Optimization Finished!\n",
      "Accuracy: 0.16768\n",
      "Epoch: 0002cost=388337.626653126\n",
      "Optimization Finished!\n",
      "Accuracy: 0.182254\n",
      "Epoch: 0003cost=298031.147092189\n",
      "Optimization Finished!\n",
      "Accuracy: 0.180044\n",
      "Epoch: 0004cost=230435.671357813\n",
      "Optimization Finished!\n",
      "Accuracy: 0.18924\n",
      "Epoch: 0005cost=179109.549642968\n",
      "Optimization Finished!\n",
      "Accuracy: 0.185537\n",
      "Epoch: 0006cost=146991.117262500\n",
      "Optimization Finished!\n",
      "Accuracy: 0.189732\n",
      "Epoch: 0007cost=118425.439243359\n",
      "Optimization Finished!\n",
      "Accuracy: 0.193719\n",
      "Epoch: 0008cost=94862.665232031\n",
      "Optimization Finished!\n",
      "Accuracy: 0.203745\n",
      "Epoch: 0009cost=80523.892810937\n",
      "Optimization Finished!\n",
      "Accuracy: 0.208489\n",
      "Epoch: 0010cost=67959.728807422\n",
      "Optimization Finished!\n",
      "Accuracy: 0.254368\n",
      "Epoch: 0011cost=57608.627510938\n",
      "Optimization Finished!\n",
      "Accuracy: 0.334671\n",
      "Epoch: 0012cost=48346.227283594\n",
      "Optimization Finished!\n",
      "Accuracy: 0.384942\n",
      "Epoch: 0013cost=41803.340131055\n",
      "Optimization Finished!\n",
      "Accuracy: 0.320255\n",
      "Epoch: 0014cost=37019.158131836\n",
      "Optimization Finished!\n",
      "Accuracy: 0.303527\n",
      "Epoch: 0015cost=32544.774030078\n",
      "Optimization Finished!\n",
      "Accuracy: 0.397151\n",
      "Epoch: 0016cost=28683.317577930\n",
      "Optimization Finished!\n",
      "Accuracy: 0.395041\n",
      "Epoch: 0017cost=25732.131551074\n",
      "Optimization Finished!\n",
      "Accuracy: 0.389147\n",
      "Epoch: 0018cost=22985.848079394\n",
      "Optimization Finished!\n",
      "Accuracy: 0.367876\n",
      "Epoch: 0019cost=21047.877277930\n",
      "Optimization Finished!\n",
      "Accuracy: 0.357061\n",
      "Epoch: 0020cost=19532.321849902\n",
      "Optimization Finished!\n",
      "Accuracy: 0.310743\n",
      "Epoch: 0021cost=18339.344827051\n",
      "Optimization Finished!\n",
      "Accuracy: 0.254321\n",
      "Epoch: 0022cost=17151.733756348\n",
      "Optimization Finished!\n",
      "Accuracy: 0.252761\n",
      "Epoch: 0023cost=16357.183329834\n",
      "Optimization Finished!\n",
      "Accuracy: 0.269555\n",
      "Epoch: 0024cost=15856.463877197\n",
      "Optimization Finished!\n",
      "Accuracy: 0.316246\n",
      "Epoch: 0025cost=15610.029598096\n",
      "Optimization Finished!\n",
      "Accuracy: 0.324728\n",
      "Epoch: 0026cost=15148.211689258\n",
      "Optimization Finished!\n",
      "Accuracy: 0.338505\n",
      "Epoch: 0027cost=14785.441936621\n",
      "Optimization Finished!\n",
      "Accuracy: 0.345655\n",
      "Epoch: 0028cost=14575.791228223\n",
      "Optimization Finished!\n",
      "Accuracy: 0.333248\n",
      "Epoch: 0029cost=14349.759950977\n",
      "Optimization Finished!\n",
      "Accuracy: 0.335372\n",
      "Epoch: 0030cost=14079.005468262\n",
      "Optimization Finished!\n",
      "Accuracy: 0.354514\n",
      "Epoch: 0031cost=13753.868612500\n",
      "Optimization Finished!\n",
      "Accuracy: 0.357753\n",
      "Epoch: 0032cost=13909.512681396\n",
      "Optimization Finished!\n",
      "Accuracy: 0.363178\n",
      "Epoch: 0033cost=13683.374709033\n",
      "Optimization Finished!\n",
      "Accuracy: 0.362148\n",
      "Epoch: 0034cost=13680.826743848\n",
      "Optimization Finished!\n",
      "Accuracy: 0.368939\n",
      "Epoch: 0035cost=13288.684248535\n",
      "Optimization Finished!\n",
      "Accuracy: 0.383446\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001 # 学習率 高いとcostの収束が早まる\n",
    "training_epochs = 100 # 学習全体をこのエポック数で区切り、区切りごとにcostを表示する\n",
    "batch_size = 5000     # 学習1回ごと( sess.run()ごと )に訓練データをいくつ利用するか\n",
    "display_step = 1     # 1なら毎エポックごとにcostを表示\n",
    "\n",
    "step_size = 5000     # 何ステップ学習するか\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 1024      # 隠れ層1のユニットの数\n",
    "n_hidden_2 = 256      # 隠れ層2のユニットの数\n",
    "n_input = 56          # 与える変数の数\n",
    "n_classes = 3        # 分類するクラスの数 今回は生き残ったか否かなので2\n",
    "\n",
    "\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]), name='h1'),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='h2'),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), name='wout')\n",
    "}\n",
    "biases = {\n",
    "    #'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    #'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    #'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    'b1': tf.Variable(tf.zeros([n_hidden_1]), name='b1'),\n",
    "    'b2': tf.Variable(tf.zeros([n_hidden_2]), name='b2'),\n",
    "    'out': tf.Variable(tf.zeros([n_classes]), name='bout')\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "print(type(pred))\n",
    "print(type(y))\n",
    "# Define loss and optimizer\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=pred,logits=y))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "#print(cost)\n",
    "#print(type(tf.train.AdamOptimizer(learning_rate=learning_rate)))\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "print(cost)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(cost)\n",
    "\n",
    "print(tf.size(pred))\n",
    "print(tf.size(y))\n",
    "#predict = []\n",
    "#for i in range(0,10):\n",
    "#    predict[i] = tf.slice(pred, [0,1], [3,2]\n",
    "#y1, y2, y3, y4, y5, y6, y7, y8, y9, y10 = tf.split(0, 10, x)\n",
    "#pred1, pred2, pred3, pred4, pred5, pred6, pred7, pred8, pred9, pred10 = tf.split(0, 10, pred)\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    #device_count={\"GPU\":0}, # GPUの数0に\n",
    "    log_device_placement=True,\n",
    "    allow_soft_placement=True\n",
    ")\n",
    "\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Launch the graph\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "\n",
    "        # Loop over step_size\n",
    "        for i in range(step_size):\n",
    "            # 訓練データから batch_size で指定した数をランダムに取得\n",
    "            ind = np.random.choice(batch_size, batch_size)\n",
    "            #print(ind)\n",
    "            x_train_batch = x_train[ind]\n",
    "            y_train_batch = y_train[ind]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: x_train_batch,\n",
    "                                                          y: y_train_batch})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / step_size\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1)+ \"cost=\"+ \"{:.9f}\".format(avg_cost))\n",
    "            print(\"Optimization Finished!\")\n",
    "            \n",
    "            if avg_cost < 0.001:#更新がなければおわり\n",
    "                break\n",
    "            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            print( \"Accuracy:\", accuracy.eval({x: x_test, y: y_test}))\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print( \"Accuracy:\", accuracy.eval({x: x_test, y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
